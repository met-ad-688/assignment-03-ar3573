{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pyspark.sql import SparkSession\n",
    "import plotly.express as px"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession.builder.appName('assignment03').getOrCreate()\n",
    "df = spark.read.csv('data/lightcast_job_postings.csv', header=True, inferSchema=True)\n",
    "df.show(5)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
,
 {
  "cell_type": "code",
  "execution_count": null,
  "metadata": {},
  "outputs": [],
  "source": [
   "# Cast salary fields to numeric\n",
   "from pyspark.sql import functions as F\n",
   "df2 = df.withColumn('SALARY_FROM', F.col('SALARY_FROM').cast('double')) \\\n",
   "        .withColumn('SALARY_TO', F.col('SALARY_TO').cast('double'))\n",
   "df2 = df2.withColumn('Average_Salary', ((F.col('SALARY_FROM') + F.col('SALARY_TO'))/2))\n",
   "\n",
   "# Compute medians\n",
   "median_from = df2.approxQuantile('SALARY_FROM', [0.5], 0.01)[0]\n",
   "median_to = df2.approxQuantile('SALARY_TO', [0.5], 0.01)[0]\n",
   "median_avg = df2.approxQuantile('Average_Salary', [0.5], 0.01)[0]\n",
   "print('Median From:', median_from)\n",
   "print('Median To:', median_to)\n",
   "print('Median Avg:', median_avg)\n",
   "\n",
   "# Clean education labels\n",
   "df2 = df2.withColumn('EDUCATION_LEVELS_NAME', F.regexp_replace('EDUCATION_LEVELS_NAME', '[\\n\\r]', ''))\n",
   "\n",
   "print('Rows retained:', df2.count())"
  ]
 }
